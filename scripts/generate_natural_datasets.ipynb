{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/jackking/anaconda/envs/modular_transformers/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to /home/jackking/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from tqdm import tqdm\n",
    "import torch as torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "nltk.download('punkt')  # Download the necessary resources\n",
    "from superurop.utilities.utils import *\n",
    "from modular_transformers.straightening.straightening_utils import compute_model_activations, compute_model_curvature\n",
    "from itertools import islice\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "dataset_manager = DatasetManager()\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")\n",
    "path = \"/om2/user/jackking/modular_transformers/scripts/attention_interpretability/\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size = 64\n",
    "dataname = \"len16_sentences\"\n",
    "context_length = 16\n",
    "buffer = 7\n",
    "dataset, params = dataset_manager.load_dataset(\"natural\", dataname)\n",
    "dataset = AutoregressiveDataset(dataset)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_sentences(fw_text):\n",
    "    sentences = []\n",
    "    # Limit with islice to avoid checking the length of sentences repeatedly\n",
    "    for i, sample in tqdm(enumerate(islice(fw_text, 1000000))):\n",
    "        tokenized_sentences = [tokenizer.encode(sentence)\n",
    "                               for sentence in sent_tokenize(sample[\"text\"])]\n",
    "        \n",
    "        # Filter and add only sentences of the required length\n",
    "        sentences.extend([s for s in tokenized_sentences if len(s) == context_length])\n",
    "\n",
    "        if i % 50000 == 0:   \n",
    "            sentences_tensor = torch.tensor(sentences)\n",
    "            params = {\"dataset_length\": len(sentences), \"context_length\": context_length, \"source\": \"fineweb\"}\n",
    "            dataset_manager.save_dataset(\"natural\", dataname, sentences_tensor, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = load_dataset(\"HuggingFaceFW/fineweb\", name=\"sample-10BT\", split=\"train\", streaming=True)\n",
    "fw_text = fw.select_columns(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "309994it [44:10, 229.33it/s]"
     ]
    }
   ],
   "source": [
    "collect_sentences(fw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(tokenizer.decode(dataset[0][i].tolist()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_whole_context_surprisals(model, dataloader, device, data_params):\n",
    "    batch_size = dataloader.batch_size\n",
    "    surprisals = torch.zeros(data_params[\"dataset_length\"], data_params[\"context_length\"])\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader)):\n",
    "        inputs = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        logits = outputs.logits\n",
    "        log_probs = -F.log_softmax(logits, dim=-1)\n",
    "        log_probs = log_probs[:, :-1, :]\n",
    "        input_ids = inputs[:, 1:]\n",
    "        indx_start = batch_idx*batch_size\n",
    "        indx_end = (batch_idx+1)*batch_size\n",
    "        surprisals[indx_start:indx_end, 1:] = log_probs.gather(-1, input_ids.unsqueeze(-1)).squeeze(-1).detach().cpu()\n",
    "\n",
    "    return surprisals\n",
    "\n",
    "\n",
    "def get_surprisals_in_context(model, dataloader, device, context_length, buffer, data_params):\n",
    "    model.eval()\n",
    "    #bad naming here. data_params[\"context_length\"] is the length of each sample, context_length is\n",
    "    # the length of the context used to calculate surprisals\n",
    "    sample_length = data_params[\"context_length\"]\n",
    "    surprisals = torch.zeros(data_params[\"dataset_length\"], sample_length)\n",
    "    context_length = context_length + 1 # the context is 2 but need to look at the third token\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader)):\n",
    "        # shape: (batch_size, sample_length-buffer-1, context_length)\n",
    "        samples_range = range(buffer-context_length+1, sample_length - context_length+1)\n",
    "        if isinstance(batch, list):\n",
    "            batch = torch.stack(batch)\n",
    "        batch = torch.stack([batch[:, i:i+context_length] for i in samples_range], axis=1).to(device)\n",
    "        batch_size = batch.shape[0]\n",
    "        sample_size = batch.shape[1]\n",
    "        flattened_batch = batch.view(batch_size*sample_size, -1)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(flattened_batch)\n",
    "        outputs = outputs.logits.view(batch_size, sample_size, context_length, -1)\n",
    "\n",
    "        for sample_idx, logits in enumerate(outputs):\n",
    "            log_probs = -F.log_softmax(logits, dim=-1)\n",
    "            log_probs = log_probs[:, -2, :]\n",
    "            input_ids = batch[sample_idx, :, -1]\n",
    "            indx_start = batch_idx*batch_size + sample_idx\n",
    "            surprisals[indx_start, buffer:] = log_probs.gather(-1, input_ids.unsqueeze(-1)).squeeze(-1).flatten().detach().cpu()\n",
    "            \n",
    "    return surprisals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2596/2596 [01:36<00:00, 26.86it/s]\n",
      "100%|██████████| 2596/2596 [02:42<00:00, 15.93it/s]\n",
      "100%|██████████| 2596/2596 [00:58<00:00, 44.51it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "model.eval()\n",
    "\n",
    "two_token_context_surprisals = get_surprisals_in_context(model, dataloader, device, 2, buffer, params) \n",
    "four_token_context_surprisals = get_surprisals_in_context(model, dataloader, device, 4, buffer, params)\n",
    "whole_context_surprisals = get_whole_context_surprisals(model, dataloader, device, params)\n",
    "\n",
    "dataset_manager.save_surprisals(\"natural\", dataname, two_token_context_surprisals, model_name, 2)\n",
    "dataset_manager.save_surprisals(\"natural\", dataname, four_token_context_surprisals, model_name, 4)\n",
    "dataset_manager.save_surprisals(\"natural\", dataname, whole_context_surprisals, model_name, \"whole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.6533,\n",
       "         7.2619, 13.9646, 11.8599,  2.4486,  9.6098,  5.3556,  9.6581,  8.4860])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_token_context_surprisals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sentences(sentences, buffer, two_token_surprisals, four_token_surprisals, whole_surprisals):\n",
    "    two_token_mean, two_token_std = torch.mean(two_token_surprisals).item(), torch.std(two_token_surprisals).item()\n",
    "    four_token_mean, four_token_std = torch.mean(four_token_surprisals).item(), torch.std(four_token_surprisals).item()\n",
    "    whole_mean, whole_std = torch.mean(whole_surprisals).item(), torch.std(whole_surprisals).item()\n",
    "    short_context_token_indices = torch.zeros(len(sentences), len(sentences[0]))\n",
    "    long_context_token_indices = torch.zeros(len(sentences), len(sentences[0]))\n",
    "    short_context_sentences_indices = []\n",
    "    long_context_sentences_indices = []\n",
    "    for sentence_idx, sentence in tqdm(enumerate(sentences)):\n",
    "        short_context_tokens = 0\n",
    "        long_context_tokens = 0\n",
    "        for token_idx in range(buffer, len(sentence)):\n",
    "            two_token_surprisal = two_token_surprisals[sentence_idx, token_idx]\n",
    "            four_token_surprisal = four_token_surprisals[sentence_idx, token_idx]\n",
    "            whole_surprisal = whole_surprisals[sentence_idx, token_idx]\n",
    "            \n",
    "            #short context clauses\n",
    "            locally_predictable = two_token_surprisal <= two_token_mean - 0.25*two_token_std\n",
    "            not_globally_predictable = whole_surprisal >= two_token_surprisal - 0.5*two_token_std #need to compare to two_token_surprisal\n",
    "            \n",
    "            #long context clauses\n",
    "            not_locally_predictable = two_token_surprisal >= two_token_mean + 0.25*two_token_std\n",
    "            mid_not_too_predictable = four_token_surprisal >= four_token_mean\n",
    "            globally_predictable = whole_surprisal <= whole_mean - 0.25*whole_std\n",
    "\n",
    "            if locally_predictable and not_globally_predictable:\n",
    "                short_context_token_indices[sentence_idx, token_idx] = 1\n",
    "                short_context_tokens += 1\n",
    "            elif not_locally_predictable and mid_not_too_predictable and globally_predictable:\n",
    "                long_context_token_indices[sentence_idx, token_idx] = 1\n",
    "                long_context_tokens += 1\n",
    "\n",
    "        if short_context_tokens > len(sentence) - buffer - 3:\n",
    "            short_context_sentences_indices.append(sentence_idx)\n",
    "        elif long_context_tokens > len(sentence) - buffer - 3:\n",
    "            long_context_sentences_indices.append(sentence_idx)\n",
    "\n",
    "    return short_context_token_indices, long_context_token_indices, np.array(short_context_sentences_indices), np.array(long_context_sentences_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166082it [00:57, 2878.46it/s]\n"
     ]
    }
   ],
   "source": [
    "two_token_context_surprisals = dataset_manager.load_surprisals(\"natural\", dataname, model_name, 2)[0]\n",
    "four_token_context_surprisals = dataset_manager.load_surprisals(\"natural\", dataname, model_name, 4)[0]\n",
    "whole_context_surprisals = dataset_manager.load_surprisals(\"natural\", dataname, model_name, \"whole\")[0]\n",
    "short_context_token_indices, long_context_token_indices, short_context_sentences, long_context_sentences = select_sentences(dataset, buffer, two_token_context_surprisals, four_token_context_surprisals, whole_context_surprisals)\n",
    "\n",
    "# dataset_manager.save_dataset(\"natural\", dataname, short_context_token_indices, model_name=model_name, context_type=\"short\", prefix=\"indices\")\n",
    "# dataset_manager.save_dataset(\"natural\", dataname, long_context_token_indices, model_name, context_type=\"long\", prefix=\"indices\")\n",
    "# dataset_manager.save_dataset(\"natural\", dataname, short_context_sentences, model_name, context_type=\"short\", prefix=\"sentences\")\n",
    "# dataset_manager.save_dataset(\"natural\", dataname, long_context_sentences, model_name, context_type=\"long\", prefix=\"sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(short_context_sentences)), print(len(long_context_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.4869e+04, 6.1978e+04, 4.6150e+04, 1.8469e+04, 4.0590e+03,\n",
       "        5.2200e+02, 3.3000e+01, 0.0000e+00, 0.0000e+00, 2.0000e+00]),\n",
       " array([0.        , 0.89999998, 1.79999995, 2.70000005, 3.5999999 ,\n",
       "        4.5       , 5.4000001 , 6.30000019, 7.19999981, 8.10000038,\n",
       "        9.        ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(short_context_token_indices.sum(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sentence_curvatures(model, sentences, datatype, dataname, model_name):\n",
    "    model.eval()\n",
    "    activations = compute_model_activations(model, sentences, device)\n",
    "    curvatures = compute_model_curvature(activations)\n",
    "    dataset_manager.save_curvatures(datatype, dataname, curvatures, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
